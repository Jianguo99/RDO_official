{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from __future__ import division\n",
    "import argparse \n",
    "import numpy as np\n",
    "import os\n",
    "import GPy\n",
    "import matplotlib.pyplot as plt\n",
    "from fipy import *\n",
    "from scipy.interpolate import griddata\n",
    "from pdb import set_trace as keyboard\n",
    "import time\n",
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating sample 100\n",
      "Generating sample 200\n",
      "Generating sample 300\n",
      "Generating sample 400\n",
      "Generating sample 500\n",
      "Generating sample 600\n",
      "Generating sample 700\n",
      "Generating sample 800\n",
      "Generating sample 900\n",
      "Generating sample 1000\n",
      "Time (sec) to generate 1000 MC samples : 35.02750372886658\n"
     ]
    }
   ],
   "source": [
    "kernels = {'rbf':GPy.kern.RBF, 'exp':GPy.kern.Exponential, \n",
    "           'mat32':GPy.kern.Matern32, 'mat52':GPy.kern.Matern52}\n",
    "\n",
    "num_samples = 1000\n",
    "nx = 127\n",
    "ellx = 0.1\n",
    "variance = 1.0\n",
    "k_ = \"exp\"\n",
    "assert k_ in kernels.keys()\n",
    "kern = kernels[k_]\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "save_path = f\"lx={ellx}\"\n",
    "if not os.path.exists(save_path):\n",
    "    os.mkdir(save_path)\n",
    "\n",
    "seed = 2022\n",
    "# Setting the seed for numpy-generated random numbers\n",
    "np.random.seed(seed=seed)\n",
    "\n",
    "# Setting the seed for python random numbers\n",
    "random.seed(seed)\n",
    "\n",
    "#define a mean function\n",
    "def mean(x):\n",
    "    \"\"\"\n",
    "    Mean of the conductivity field. \n",
    "\n",
    "    m(x) = 0. \n",
    "    \"\"\"\n",
    "    n = x.shape[0]\n",
    "    return np.zeros((n, 1))\n",
    "\n",
    "#GPy kernel\n",
    "k = kern(1, lengthscale = ellx, variance = variance)\n",
    "\n",
    "#defining mesh to get cellcenters\n",
    "Lx = 1.  # always put . after 1 \n",
    "mesh = Grid1D(nx=nx, dx=Lx/nx) # with nx number of cells/cellcenters/pixels/pixelcenters\n",
    "cellcenters = mesh.cellCenters.value.T  #(nx,1) matrix\n",
    "cellcenters_all = np.concatenate((np.zeros((1,1)),cellcenters,np.ones((1,1))))\n",
    "np.save(f\"{save_path}/coordinates_nx=\"+str(nx)+\".npy\", cellcenters)\n",
    "\n",
    "\n",
    "#get covariance matrix and compute its Cholesky decomposition\n",
    "m = mean(cellcenters_all)\n",
    "nugget = 1e-6 # This is a small number required for stability\n",
    "Cov = k.K(cellcenters_all) + nugget * np.eye(cellcenters_all.shape[0])\n",
    "L = np.linalg.cholesky(Cov)\n",
    "\n",
    "#define matrices to save results \n",
    "inputs = np.zeros((num_samples, nx))\n",
    "inputsall = np.zeros((num_samples, nx+2))\n",
    "outputs = np.zeros((num_samples, nx))\n",
    "\n",
    "start = time.time()\n",
    "#generate samples\n",
    "for i in range(num_samples):\n",
    "    #display\n",
    "    if (i+1)%100 == 0:\n",
    "        print(\"Generating sample \"+str(i+1))\n",
    "    \n",
    "    #generate a sample of the random field input\n",
    "    z = np.random.randn(cellcenters_all.shape[0], 1)\n",
    "    f = m + np.dot(L, z)\n",
    "    sample_all = np.exp(f) # 'sample' is one image of input field: conductivity image\n",
    "\n",
    "    # bounding input fields from below and above\n",
    "    lower_bound =  np.exp(-5.298317366548036) # 0.005000000000000002\n",
    "    upper_bound =  np.exp(3.5) # 33.11545195869231 \n",
    "\n",
    "    sample_all = np.where(sample_all < lower_bound, lower_bound, sample_all) \n",
    "    sample_all  = np.where(sample_all > upper_bound, upper_bound, sample_all) \n",
    "    sample =sample_all[1:-1]\n",
    "\n",
    "\n",
    "    #FIPY solution\n",
    "    value_left = 1\n",
    "    value_right = 0\n",
    " \n",
    "    # define cell and face variables\n",
    "    phi = CellVariable(name='$T(x)$', mesh=mesh, value=0.)\n",
    "    D = CellVariable(name='$D(x)$', mesh=mesh, value=1.0) ## coefficient in diffusion equation\n",
    "    # D = FaceVariable(name='$D(x)$', mesh=mesh, value=1.0) ## coefficient in diffusion equation\n",
    "    source = CellVariable(name='$f(x)$', mesh=mesh, value=1.0)\n",
    "    C = CellVariable(name='$C(x)$', mesh=mesh, value=1.0)\n",
    "\n",
    "    # apply boundary conditions\n",
    "    # dirichet\n",
    "    phi.constrain(value_left, mesh.facesLeft)\n",
    "    phi.constrain(value_right, mesh.facesRight)\n",
    "    \n",
    "    # setup the diffusion problem\n",
    "    eq = -DiffusionTerm(coeff=D)+ImplicitSourceTerm(coeff=C) == source\n",
    "\n",
    "    c = 15.\n",
    "    f = 10. #source\n",
    "\n",
    "    source.setValue(f)\n",
    "    C.setValue(c)\n",
    "\n",
    "    D.setValue(sample.ravel())\n",
    "\n",
    "    eq.solve(var=phi)\n",
    "    x_fipy = mesh.cellCenters.value.T ## fipy solution (nx,1) matrix # same as cellcenters defined above\n",
    "    u_fipy = phi.value[:][:, None] ## fipy solution  (nx,1) matrix\n",
    "\n",
    "    # x_face=mesh.faceCenters.value.flatten() #cell faces location i.e.edges of the element \n",
    "    # y_face=phi.faceValue()                  #cell faces location i.e.edges of the element\n",
    "  \n",
    "    #save data \n",
    "    inputs[i] = sample.ravel()\n",
    "    inputsall[i] = sample_all.ravel()\n",
    "    outputs[i] = u_fipy.flatten()   \n",
    "\n",
    "#end timer\n",
    "finish = time.time() - start\n",
    "print(\"Time (sec) to generate \"+str(num_samples)+\" MC samples : \" +str(finish))\n",
    "\n",
    "# print np.shape(inputs)\n",
    "# print np.shape(outputs)\n",
    "# print inputs\n",
    "# print outputs\n",
    "\n",
    "#save data\n",
    "np.save(f\"{save_path}/MC_samples_inputfield_\"+\\\n",
    "            k_+\"_nx=\"+str(nx)+\\\n",
    "            \"_lx=\"+str(ellx)+\\\n",
    "            \"_v=\"+str(variance)+\\\n",
    "            \"_num_samples=\"+str(num_samples)+\".npy\", inputs)\n",
    "\n",
    "\n",
    "np.save(f\"{save_path}/MC_samples_inputfield_wBoundary_\"+\\\n",
    "            k_+\"_nx=\"+str(nx)+\\\n",
    "            \"_lx=\"+str(ellx)+\\\n",
    "            \"_v=\"+str(variance)+\\\n",
    "            \"_num_samples=\"+str(num_samples)+\".npy\", inputsall)\n",
    "\n",
    "\n",
    "np.save(f\"{save_path}/MC_samples_u_fipy_\"+\\\n",
    "            k_+\"_nx=\"+str(nx)+\\\n",
    "            \"_lx=\"+str(ellx)+\\\n",
    "            \"_v=\"+str(variance)+\\\n",
    "            \"_num_samples=\"+str(num_samples)+\".npy\", outputs)\n",
    "\n",
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 129)\n",
      "(129, 1)\n",
      "(1000, 129)\n"
     ]
    }
   ],
   "source": [
    "path1 = f\"{save_path}/MC_samples_u_fipy_\"+\\\n",
    "            k_+\"_nx=\"+str(nx)+\\\n",
    "            \"_lx=\"+str(ellx)+\\\n",
    "            \"_v=\"+str(variance)+\\\n",
    "            \"_num_samples=\"+str(num_samples)+\".npy\"\n",
    "\n",
    "\n",
    "path3 = f\"{save_path}/MC_samples_inputfield_wBoundary_\"+\\\n",
    "            k_+\"_nx=\"+str(nx)+\\\n",
    "            \"_lx=\"+str(ellx)+\\\n",
    "            \"_v=\"+str(variance)+\\\n",
    "            \"_num_samples=\"+str(num_samples)+\".npy\"\n",
    "\n",
    "\n",
    "path2 = f\"{save_path}/MC_samples_inputfield_\"+\\\n",
    "            k_+\"_nx=\"+str(nx)+\\\n",
    "            \"_lx=\"+str(ellx)+\\\n",
    "            \"_v=\"+str(variance)+\\\n",
    "            \"_num_samples=\"+str(num_samples)+\".npy\"\n",
    "\n",
    "cellcenters_nx = np.load(f\"{save_path}/coordinates_nx=\"+str(nx)+\".npy\")\n",
    "cellcenters_nx = np.concatenate((np.zeros((1,1)),cellcenters_nx,np.ones((1,1))))\n",
    "np.save(f\"{save_path}/coordinates_nx=\"+str(cellcenters_nx.shape[0])+\".npy\", cellcenters_nx)\n",
    "\n",
    "trainDataInputfield= np.load(path3)\n",
    "trainDataU = np.load(path1)\n",
    "\n",
    "trainDataU = np.concatenate((np.ones((trainDataU.shape[0],1)),trainDataU,np.zeros((trainDataU.shape[0],1))),axis=1)\n",
    "\n",
    "\n",
    "print(trainDataInputfield.shape)\n",
    "print(cellcenters_nx.shape)\n",
    "print(trainDataU.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(129, 1)\n",
      "1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['lx=0.1/TestData.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "DataU  = trainDataU\n",
    "DataInputfield = trainDataInputfield\n",
    "coordinates_inputfield = cellcenters_nx  \n",
    "coordinates_ouput = cellcenters_nx  \n",
    "print(coordinates_ouput.shape)\n",
    "\n",
    "joblib.dump(coordinates_inputfield,f\"{save_path}/coordinates_inputfield.pkl\") \n",
    "joblib.dump(coordinates_ouput,f\"{save_path}/coordinates_output.pkl\") \n",
    "\n",
    "\n",
    "allNum = DataInputfield.shape[0]\n",
    "print(allNum)\n",
    "trainNumExamples,valNumExamples, = int(allNum*0.6),int(allNum*0.2)\n",
    "\n",
    "TrainData={}\n",
    "TrainData['coeff'] = DataInputfield[:trainNumExamples,:]\n",
    "TrainData['sol'] = DataU[:trainNumExamples,:]\n",
    "\n",
    "ValData={}\n",
    "ValData['coeff'] = DataInputfield[trainNumExamples:(trainNumExamples+valNumExamples),:]\n",
    "ValData['sol'] = DataU[trainNumExamples:(trainNumExamples+valNumExamples),:]\n",
    "\n",
    "TestData={}\n",
    "TestData['coeff'] = DataInputfield[(trainNumExamples+valNumExamples):,:]\n",
    "TestData['sol'] = DataU[(trainNumExamples+valNumExamples):,:]\n",
    "\n",
    "joblib.dump(TrainData,f\"{save_path}/TrainData.pkl\")\n",
    "joblib.dump(ValData,f\"{save_path}/ValData.pkl\")\n",
    "joblib.dump(TestData,f\"{save_path}/TestData.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
